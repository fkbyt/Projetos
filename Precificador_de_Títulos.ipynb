{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import lxml\n",
    "import re\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"vértices\":[],\n",
    "        \"ETTJ IPCA\":[],\n",
    "        \"ETTJ PRE\":[],\n",
    "        \"Inflação Implícita\":[],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adidata(resultado):\n",
    "    if len(resultado) == 4:\n",
    "        data['vértices'].append(int(resultado[0].replace('.',\"\")))\n",
    "        data['ETTJ IPCA'].append(float(resultado[1].replace(',','.')))\n",
    "        data['ETTJ PRE'].append(float(resultado[2].replace(',','.')))\n",
    "        data['Inflação Implícita'].append(float(resultado[3].replace(',','.')))\n",
    "    elif len(resultado) == 2:\n",
    "        data['vértices'].append(int(resultado[0].replace('.',\"\")))\n",
    "        data['ETTJ IPCA'].append(float(resultado[1].replace(',',\".\")))\n",
    "        data['ETTJ PRE'].append(None)\n",
    "        data['Inflação Implícita'].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_ettj():\n",
    "    \n",
    "    res = requests.get(\"https://www.anbima.com.br/informacoes/est-termo/CZ.asp\")\n",
    "    soup = bs4.BeautifulSoup(res.text,'lxml')\n",
    "\n",
    "    for i, tr in enumerate(soup.select('table')[6].select('tr')):\n",
    "        if i < 5:\n",
    "            for i, td in enumerate(tr.select('td')):\n",
    "                if i < 2:\n",
    "                    if re.search(r'\\b\\d{2}(?![,.])\\b', td.text):\n",
    "                        resultado = re.search(r'\\b\\d{2}(?![,.])\\b', td.text)\n",
    "                        data['vértices'].append(int(resultado[0].replace(',',\"\")))\n",
    "                        data['ETTJ IPCA'].append(None)\n",
    "                        data['Inflação Implícita'].append(None)\n",
    "                    elif re.search(r'\\d+,\\d+',td.text):\n",
    "                        resultado = re.search(r'\\d+,\\d+',td.text)\n",
    "                        data['ETTJ PRE'].append(float(resultado[0].replace(',',\".\")))\n",
    "    \n",
    "    for item in soup.select('table')[5].select('tr'):\n",
    "        resultado = re.findall(r'(?<!/)\\d\\d\\d|(?<!/)\\d+,\\d+|(?<!/)\\d+.\\d+', item.text)\n",
    "        adidata(resultado)\n",
    "    \n",
    "    return pandas.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\felip\\anaconda3\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = criar_ettj()\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamar_feriados():\n",
    "    dados_feriados = pandas.read_excel(\"feriados_nacionais.xls\")\n",
    "    for i, d in enumerate(dados_feriados['Data']):\n",
    "        if issubclass(type(d),datetime.datetime):\n",
    "         pass\n",
    "        else:\n",
    "            dados_feriados = dados_feriados.drop(index=i)\n",
    "    z = numpy.array(dados_feriados['Data'])\n",
    "    z = z.astype('datetime64[D]')\n",
    "    dados_feriados['Data'] = z\n",
    "    return dados_feriados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feriados = chamar_feriados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_vértices = df['vértices'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_feriados(data_1,data_2):\n",
    "    holydays = df_feriados.loc[(df_feriados['Data'] > data_1) & (df_feriados['Data'] < data_2)]['Data']\n",
    "    holydays = numpy.array(holydays)\n",
    "    holydays = holydays.astype('datetime64[D]')\n",
    "    return holydays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_du(data_1,data_2,holydays):\n",
    "    dias_uteis = numpy.busday_count(data_1, data_2, '1111100', holydays)\n",
    "    return dias_uteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxa_interpolada_linear(dias_uteis):\n",
    "    tx_1 = []\n",
    "    tx_2 = []\n",
    "    \n",
    "    for i in range(len(lista_vértices)-1):\n",
    "        if lista_vértices[i] <= dias_uteis <= lista_vértices[i+1]:\n",
    "            par = (lista_vértices[i],lista_vértices[i+1])\n",
    "\n",
    "    indice = df[df['vértices'] == par[0]].index.to_list()\n",
    "    indice = indice[0]\n",
    "\n",
    "    tx_1.append(df[df.index == indice]['vértices'].values[0])\n",
    "    tx_1.append(df[df.index == indice]['ETTJ PRE'].values[0])\n",
    "    tx_2.append(df[df.index == indice+1]['vértices'].values[0])\n",
    "    tx_2.append(df[df.index == indice+1]['ETTJ PRE'].values[0])\n",
    "\n",
    "    tx_linear = tx_1[1] + (dias_uteis -tx_1[0])*(tx_2[1]-tx_1[1])/(tx_2[0]-tx_1[0])\n",
    "    tx_linear = tx_linear/100\n",
    "    \n",
    "    return tx_linear\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_fluxo(data_2, data_1, fluxo, feriado):\n",
    "    d = data_2\n",
    "    while d > data_1:\n",
    "        fluxo['Data Nominal'].append(d)\n",
    "        if numpy.is_busday(d, holidays=feriado):\n",
    "            d = numpy.busday_offset(d,offsets=0,roll='forward', holidays=feriado)\n",
    "        fluxo['Data Efetiva'].append(d) \n",
    "\n",
    "        d = d - pandas.offsets.DateOffset(months=6)\n",
    "        d = d.to_datetime64()\n",
    "        d = d.astype('datetime64[D]')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxos = {\n",
    "        \"Data Nominal\": [],\n",
    "        \"Data Efetiva\":[],\n",
    "        \"Dias úteis\":[],\n",
    "        \"Fluxo %\":[],\n",
    "        \"Fluxo VP\":[],\n",
    "        \"Fluxo Monetário\":[],\n",
    "    }\n",
    "\n",
    "data1 = datetime.datetime.today()\n",
    "data2 = datetime.datetime(2027,7,1)\n",
    "data1 = numpy.datetime64(data1, 'D')\n",
    "data2 = numpy.datetime64(data2, 'D')\n",
    "\n",
    "cupom = 0.06\n",
    "valor_face = 3000\n",
    "\n",
    "feriados = calcular_feriados(data1,data2)\n",
    "\n",
    "criar_fluxo(data2, data1, fluxos, feriados)\n",
    "\n",
    "for i, data in enumerate(fluxos['Data Efetiva']):\n",
    "    if i == 0:\n",
    "        du = calcular_du(data1, data, feriados)\n",
    "        fluxos['Dias úteis'].append(du)\n",
    "        taxa = taxa_interpolada_linear(du)\n",
    "\n",
    "        f_p = 1 + cupom\n",
    "        fluxos[\"Fluxo %\"].append(f_p)\n",
    "\n",
    "        f_p_vp = (f_p)/(1+taxa)**(abs(du)/252)\n",
    "        fluxos[\"Fluxo VP\"].append(f_p_vp) \n",
    "\n",
    "        f_m_vp = f_p_vp*valor_face\n",
    "        fluxos[\"Fluxo Monetário\"].append(f_m_vp)\n",
    "\n",
    "    else:\n",
    "        du = calcular_du(data1, data, feriados)\n",
    "        fluxos['Dias úteis'].append(du)\n",
    "        taxa = taxa_interpolada_linear(du)\n",
    "\n",
    "        f_p = cupom\n",
    "        fluxos[\"Fluxo %\"].append(f_p)\n",
    "\n",
    "        f_p_vp = (f_p)/(1+taxa)**(abs(du)/252)\n",
    "        fluxos[\"Fluxo VP\"].append(f_p_vp) \n",
    "\n",
    "        f_m_vp = f_p_vp*valor_face\n",
    "        fluxos[\"Fluxo Monetário\"].append(f_m_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fluxos = pandas.DataFrame(fluxos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fluxos['Data Nominal'] = df_fluxos['Data Nominal'].dt.strftime('%d/%m/%Y')\n",
    "df_fluxos['Data Efetiva'] = df_fluxos['Data Efetiva'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fluxos.to_excel('fluxo1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
